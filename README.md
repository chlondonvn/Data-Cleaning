
# <img src="https://bit.ly/2VnXWr2" alt="Ironhack Logo" width="100"/>

# Data Cleaning
*Charlotte Velilla Nunez*

*[DATA ANALYSIS 08-20, Berlin & 23.08.20]*

## Content
- [Project Description](#project-description)
- [Questions & Hypotheses](#questions-hypotheses)
- [Dataset](#dataset)
- [Database](#database)
- [Workflow](#workflow)
- [Organization](#organization)
- [Links](#links)

## Project Description
Using Pandas to clean the Data Frame 'GSAF5.csv'.

## Questions & Hypotheses
Questions regarding data cleaning: What is the relevance of the data in each column? Is the presence of multiple NaN values criteria enough to discard columns? What is included in the data that can be deleted?  

The answersto this questions prior cleaning the data were contemplated as follow: there will be irrelevant data present, the presence of multiple NaN values is not criteria enough to drop columns from Data Frame, perhaps there will be vague descriptions included that are not relevant or useful for the understanding of shark attacks. 

## Dataset
Dataset = 'Attacks.csv'
Original source of dataset: http://www.sharkattackfile.net/index.htm
Link to messy dataset:  https://www.kaggle.com/teajay/global-shark-attacks/version/1

Description of Dataset: This is a table of shark attack incidents compiled by the Global Shark Attack File.


## Database

Structure of database given is one table.

## Workflow
For more information and description of each step taken please see the Jupyter Notebook File included.

## Organization

The initial data frame was evaluated and called with head(), then an understanding of the shape() of the data frame was made.  The work organization started after a "sketch" of a viable clean table was produced and after this "sketch" was made, the steps in order to achieve the new data frame were listed and followed.

## Links

[Repository]https://github.com/chlondonvn/Data-Cleaning

